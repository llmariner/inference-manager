// Code generated by protoc-gen-go. DO NOT EDIT.
// versions:
// 	protoc-gen-go v1.34.1
// 	protoc        (unknown)
// source: api/v1/inference_server_model_response.proto

package v1

import (
	_ "google.golang.org/genproto/googleapis/api/annotations"
	protoreflect "google.golang.org/protobuf/reflect/protoreflect"
	protoimpl "google.golang.org/protobuf/runtime/protoimpl"
	reflect "reflect"
	sync "sync"
)

const (
	// Verify that this generated code is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(20 - protoimpl.MinVersion)
	// Verify that runtime/protoimpl is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(protoimpl.MaxVersion - 20)
)

type CreateModelResponseRequest struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	Background bool     `protobuf:"varint,1,opt,name=background,proto3" json:"background,omitempty"`
	Include    []string `protobuf:"bytes,2,rep,name=include,proto3" json:"include,omitempty"`
	// The type of the input is either string or array in the OpenAI API spec, but
	// we only support the array type here. When a client sends a string, it is converted before
	// the request is being unmarshalled.
	Input              []*CreateModelResponseRequest_Input       `protobuf:"bytes,3,rep,name=input,proto3" json:"input,omitempty"`
	Instructions       string                                    `protobuf:"bytes,4,opt,name=instructions,proto3" json:"instructions,omitempty"`
	MaxOutputTokens    int32                                     `protobuf:"varint,5,opt,name=max_output_tokens,json=maxOutputTokens,proto3" json:"max_output_tokens,omitempty"`
	MaxToolCalls       int32                                     `protobuf:"varint,6,opt,name=max_tool_calls,json=maxToolCalls,proto3" json:"max_tool_calls,omitempty"`
	Metadata           map[string]string                         `protobuf:"bytes,7,rep,name=metadata,proto3" json:"metadata,omitempty" protobuf_key:"bytes,1,opt,name=key,proto3" protobuf_val:"bytes,2,opt,name=value,proto3"`
	Model              string                                    `protobuf:"bytes,8,opt,name=model,proto3" json:"model,omitempty"`
	ParallelToolCalls  bool                                      `protobuf:"varint,9,opt,name=parallel_tool_calls,json=parallelToolCalls,proto3" json:"parallel_tool_calls,omitempty"`
	PreviousResponseId string                                    `protobuf:"bytes,10,opt,name=previous_response_id,json=previousResponseId,proto3" json:"previous_response_id,omitempty"`
	Prompt             *CreateModelResponseRequest_Prompt        `protobuf:"bytes,11,opt,name=prompt,proto3" json:"prompt,omitempty"`
	PromptCacheKey     string                                    `protobuf:"bytes,12,opt,name=prompt_cache_key,json=promptCacheKey,proto3" json:"prompt_cache_key,omitempty"`
	Reasoning          *CreateModelResponseRequest_Reasoning     `protobuf:"bytes,13,opt,name=reasoning,proto3" json:"reasoning,omitempty"`
	SafetyIdentifier   string                                    `protobuf:"bytes,14,opt,name=safety_identifier,json=safetyIdentifier,proto3" json:"safety_identifier,omitempty"`
	ServiceTier        string                                    `protobuf:"bytes,15,opt,name=service_tier,json=serviceTier,proto3" json:"service_tier,omitempty"`
	Store              bool                                      `protobuf:"varint,16,opt,name=store,proto3" json:"store,omitempty"`
	Stream             bool                                      `protobuf:"varint,17,opt,name=stream,proto3" json:"stream,omitempty"`
	StreamOptions      *CreateModelResponseRequest_StreamOptions `protobuf:"bytes,18,opt,name=stream_options,json=streamOptions,proto3" json:"stream_options,omitempty"`
	Temperature        float64                                   `protobuf:"fixed64,19,opt,name=temperature,proto3" json:"temperature,omitempty"`
	// is_temperature_set is used to indicate whether the temperature is set or not.
	// This is required as the OpenAI API spec uses 1.0 as the default value for temperature while
	// setting temperature to 0.0 in the proto is equivalent to unset. If the user sets temperature to 0.0,
	// it becomes unset when the request is sent to the engine (and then the inference runtime sets temperature to 1.0
	// as that's the default value).
	IsTemperatureSet bool                             `protobuf:"varint,20,opt,name=is_temperature_set,json=isTemperatureSet,proto3" json:"is_temperature_set,omitempty"`
	Text             *CreateModelResponseRequest_Text `protobuf:"bytes,21,opt,name=text,proto3" json:"text,omitempty"`
	// The type of the "tool_choice" field is a string or an object.
	// As we cannot have a string or an object in the proto, we use the "tool_choice_object"
	// if a request sets the "tool_choice" field as an object.
	//
	// The "tool_choice_object" field is converted to the "tool_choice" field when the request is being
	// sent to an inference runtime.
	ToolChoice       string                                 `protobuf:"bytes,22,opt,name=tool_choice,json=toolChoice,proto3" json:"tool_choice,omitempty"`
	ToolChoiceObject *CreateModelResponseRequest_ToolChoice `protobuf:"bytes,23,opt,name=tool_choice_object,json=toolChoiceObject,proto3" json:"tool_choice_object,omitempty"`
	TopLogprobs      int32                                  `protobuf:"varint,24,opt,name=top_logprobs,json=topLogprobs,proto3" json:"top_logprobs,omitempty"`
	TopP             float64                                `protobuf:"fixed64,25,opt,name=top_p,json=topP,proto3" json:"top_p,omitempty"`
	// is_top_p_set is used to indicate whether the top_p is set or not.
	// This is required as the OpenAI API spec uses 1.0 as the default value for top_p while
	// setting top_p to 0.0 in the proto is equivalent to unset. If the user sets top_p to 0.0,
	// it becomes unset when the request is sent to the engine (and then the inference runtime sets top_p to 1.0
	// as that's the default value).
	IsTopPSet  bool   `protobuf:"varint,26,opt,name=is_top_p_set,json=isTopPSet,proto3" json:"is_top_p_set,omitempty"`
	Truncation bool   `protobuf:"varint,27,opt,name=truncation,proto3" json:"truncation,omitempty"`
	User       string `protobuf:"bytes,28,opt,name=user,proto3" json:"user,omitempty"`
}

func (x *CreateModelResponseRequest) Reset() {
	*x = CreateModelResponseRequest{}
	if protoimpl.UnsafeEnabled {
		mi := &file_api_v1_inference_server_model_response_proto_msgTypes[0]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *CreateModelResponseRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*CreateModelResponseRequest) ProtoMessage() {}

func (x *CreateModelResponseRequest) ProtoReflect() protoreflect.Message {
	mi := &file_api_v1_inference_server_model_response_proto_msgTypes[0]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use CreateModelResponseRequest.ProtoReflect.Descriptor instead.
func (*CreateModelResponseRequest) Descriptor() ([]byte, []int) {
	return file_api_v1_inference_server_model_response_proto_rawDescGZIP(), []int{0}
}

func (x *CreateModelResponseRequest) GetBackground() bool {
	if x != nil {
		return x.Background
	}
	return false
}

func (x *CreateModelResponseRequest) GetInclude() []string {
	if x != nil {
		return x.Include
	}
	return nil
}

func (x *CreateModelResponseRequest) GetInput() []*CreateModelResponseRequest_Input {
	if x != nil {
		return x.Input
	}
	return nil
}

func (x *CreateModelResponseRequest) GetInstructions() string {
	if x != nil {
		return x.Instructions
	}
	return ""
}

func (x *CreateModelResponseRequest) GetMaxOutputTokens() int32 {
	if x != nil {
		return x.MaxOutputTokens
	}
	return 0
}

func (x *CreateModelResponseRequest) GetMaxToolCalls() int32 {
	if x != nil {
		return x.MaxToolCalls
	}
	return 0
}

func (x *CreateModelResponseRequest) GetMetadata() map[string]string {
	if x != nil {
		return x.Metadata
	}
	return nil
}

func (x *CreateModelResponseRequest) GetModel() string {
	if x != nil {
		return x.Model
	}
	return ""
}

func (x *CreateModelResponseRequest) GetParallelToolCalls() bool {
	if x != nil {
		return x.ParallelToolCalls
	}
	return false
}

func (x *CreateModelResponseRequest) GetPreviousResponseId() string {
	if x != nil {
		return x.PreviousResponseId
	}
	return ""
}

func (x *CreateModelResponseRequest) GetPrompt() *CreateModelResponseRequest_Prompt {
	if x != nil {
		return x.Prompt
	}
	return nil
}

func (x *CreateModelResponseRequest) GetPromptCacheKey() string {
	if x != nil {
		return x.PromptCacheKey
	}
	return ""
}

func (x *CreateModelResponseRequest) GetReasoning() *CreateModelResponseRequest_Reasoning {
	if x != nil {
		return x.Reasoning
	}
	return nil
}

func (x *CreateModelResponseRequest) GetSafetyIdentifier() string {
	if x != nil {
		return x.SafetyIdentifier
	}
	return ""
}

func (x *CreateModelResponseRequest) GetServiceTier() string {
	if x != nil {
		return x.ServiceTier
	}
	return ""
}

func (x *CreateModelResponseRequest) GetStore() bool {
	if x != nil {
		return x.Store
	}
	return false
}

func (x *CreateModelResponseRequest) GetStream() bool {
	if x != nil {
		return x.Stream
	}
	return false
}

func (x *CreateModelResponseRequest) GetStreamOptions() *CreateModelResponseRequest_StreamOptions {
	if x != nil {
		return x.StreamOptions
	}
	return nil
}

func (x *CreateModelResponseRequest) GetTemperature() float64 {
	if x != nil {
		return x.Temperature
	}
	return 0
}

func (x *CreateModelResponseRequest) GetIsTemperatureSet() bool {
	if x != nil {
		return x.IsTemperatureSet
	}
	return false
}

func (x *CreateModelResponseRequest) GetText() *CreateModelResponseRequest_Text {
	if x != nil {
		return x.Text
	}
	return nil
}

func (x *CreateModelResponseRequest) GetToolChoice() string {
	if x != nil {
		return x.ToolChoice
	}
	return ""
}

func (x *CreateModelResponseRequest) GetToolChoiceObject() *CreateModelResponseRequest_ToolChoice {
	if x != nil {
		return x.ToolChoiceObject
	}
	return nil
}

func (x *CreateModelResponseRequest) GetTopLogprobs() int32 {
	if x != nil {
		return x.TopLogprobs
	}
	return 0
}

func (x *CreateModelResponseRequest) GetTopP() float64 {
	if x != nil {
		return x.TopP
	}
	return 0
}

func (x *CreateModelResponseRequest) GetIsTopPSet() bool {
	if x != nil {
		return x.IsTopPSet
	}
	return false
}

func (x *CreateModelResponseRequest) GetTruncation() bool {
	if x != nil {
		return x.Truncation
	}
	return false
}

func (x *CreateModelResponseRequest) GetUser() string {
	if x != nil {
		return x.User
	}
	return ""
}

type ModelResponse struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields
}

func (x *ModelResponse) Reset() {
	*x = ModelResponse{}
	if protoimpl.UnsafeEnabled {
		mi := &file_api_v1_inference_server_model_response_proto_msgTypes[1]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *ModelResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ModelResponse) ProtoMessage() {}

func (x *ModelResponse) ProtoReflect() protoreflect.Message {
	mi := &file_api_v1_inference_server_model_response_proto_msgTypes[1]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ModelResponse.ProtoReflect.Descriptor instead.
func (*ModelResponse) Descriptor() ([]byte, []int) {
	return file_api_v1_inference_server_model_response_proto_rawDescGZIP(), []int{1}
}

type CreateModelResponseRequest_Input struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	Type string `protobuf:"bytes,1,opt,name=type,proto3" json:"type,omitempty"`
	// The type of the content is either string or array in the OpenAI API spec, but
	// we only support the array type here. When a client sends a string, it is converted before
	// the request is being unmarshalled.
	Content []*CreateModelResponseRequest_Input_Content `protobuf:"bytes,2,rep,name=content,proto3" json:"content,omitempty"`
	Role    string                                      `protobuf:"bytes,3,opt,name=role,proto3" json:"role,omitempty"`
	Status  string                                      `protobuf:"bytes,4,opt,name=status,proto3" json:"status,omitempty"`
	// id is only meaningful when the type is "item_reference" or "message" (and the item is an output message).
	Id string `protobuf:"bytes,5,opt,name=id,proto3" json:"id,omitempty"`
}

func (x *CreateModelResponseRequest_Input) Reset() {
	*x = CreateModelResponseRequest_Input{}
	if protoimpl.UnsafeEnabled {
		mi := &file_api_v1_inference_server_model_response_proto_msgTypes[2]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *CreateModelResponseRequest_Input) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*CreateModelResponseRequest_Input) ProtoMessage() {}

func (x *CreateModelResponseRequest_Input) ProtoReflect() protoreflect.Message {
	mi := &file_api_v1_inference_server_model_response_proto_msgTypes[2]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use CreateModelResponseRequest_Input.ProtoReflect.Descriptor instead.
func (*CreateModelResponseRequest_Input) Descriptor() ([]byte, []int) {
	return file_api_v1_inference_server_model_response_proto_rawDescGZIP(), []int{0, 0}
}

func (x *CreateModelResponseRequest_Input) GetType() string {
	if x != nil {
		return x.Type
	}
	return ""
}

func (x *CreateModelResponseRequest_Input) GetContent() []*CreateModelResponseRequest_Input_Content {
	if x != nil {
		return x.Content
	}
	return nil
}

func (x *CreateModelResponseRequest_Input) GetRole() string {
	if x != nil {
		return x.Role
	}
	return ""
}

func (x *CreateModelResponseRequest_Input) GetStatus() string {
	if x != nil {
		return x.Status
	}
	return ""
}

func (x *CreateModelResponseRequest_Input) GetId() string {
	if x != nil {
		return x.Id
	}
	return ""
}

type CreateModelResponseRequest_Prompt struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	Id string `protobuf:"bytes,1,opt,name=id,proto3" json:"id,omitempty"`
	// TODO(kenji): Support variables
	Version string `protobuf:"bytes,3,opt,name=version,proto3" json:"version,omitempty"`
}

func (x *CreateModelResponseRequest_Prompt) Reset() {
	*x = CreateModelResponseRequest_Prompt{}
	if protoimpl.UnsafeEnabled {
		mi := &file_api_v1_inference_server_model_response_proto_msgTypes[3]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *CreateModelResponseRequest_Prompt) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*CreateModelResponseRequest_Prompt) ProtoMessage() {}

func (x *CreateModelResponseRequest_Prompt) ProtoReflect() protoreflect.Message {
	mi := &file_api_v1_inference_server_model_response_proto_msgTypes[3]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use CreateModelResponseRequest_Prompt.ProtoReflect.Descriptor instead.
func (*CreateModelResponseRequest_Prompt) Descriptor() ([]byte, []int) {
	return file_api_v1_inference_server_model_response_proto_rawDescGZIP(), []int{0, 1}
}

func (x *CreateModelResponseRequest_Prompt) GetId() string {
	if x != nil {
		return x.Id
	}
	return ""
}

func (x *CreateModelResponseRequest_Prompt) GetVersion() string {
	if x != nil {
		return x.Version
	}
	return ""
}

type CreateModelResponseRequest_Reasoning struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	Effort          string `protobuf:"bytes,1,opt,name=effort,proto3" json:"effort,omitempty"`
	GenerateSummary string `protobuf:"bytes,2,opt,name=generate_summary,json=generateSummary,proto3" json:"generate_summary,omitempty"`
	Summary         string `protobuf:"bytes,3,opt,name=summary,proto3" json:"summary,omitempty"`
}

func (x *CreateModelResponseRequest_Reasoning) Reset() {
	*x = CreateModelResponseRequest_Reasoning{}
	if protoimpl.UnsafeEnabled {
		mi := &file_api_v1_inference_server_model_response_proto_msgTypes[4]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *CreateModelResponseRequest_Reasoning) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*CreateModelResponseRequest_Reasoning) ProtoMessage() {}

func (x *CreateModelResponseRequest_Reasoning) ProtoReflect() protoreflect.Message {
	mi := &file_api_v1_inference_server_model_response_proto_msgTypes[4]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use CreateModelResponseRequest_Reasoning.ProtoReflect.Descriptor instead.
func (*CreateModelResponseRequest_Reasoning) Descriptor() ([]byte, []int) {
	return file_api_v1_inference_server_model_response_proto_rawDescGZIP(), []int{0, 2}
}

func (x *CreateModelResponseRequest_Reasoning) GetEffort() string {
	if x != nil {
		return x.Effort
	}
	return ""
}

func (x *CreateModelResponseRequest_Reasoning) GetGenerateSummary() string {
	if x != nil {
		return x.GenerateSummary
	}
	return ""
}

func (x *CreateModelResponseRequest_Reasoning) GetSummary() string {
	if x != nil {
		return x.Summary
	}
	return ""
}

type CreateModelResponseRequest_StreamOptions struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	IncludeObfuscation bool `protobuf:"varint,1,opt,name=include_obfuscation,json=includeObfuscation,proto3" json:"include_obfuscation,omitempty"`
}

func (x *CreateModelResponseRequest_StreamOptions) Reset() {
	*x = CreateModelResponseRequest_StreamOptions{}
	if protoimpl.UnsafeEnabled {
		mi := &file_api_v1_inference_server_model_response_proto_msgTypes[5]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *CreateModelResponseRequest_StreamOptions) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*CreateModelResponseRequest_StreamOptions) ProtoMessage() {}

func (x *CreateModelResponseRequest_StreamOptions) ProtoReflect() protoreflect.Message {
	mi := &file_api_v1_inference_server_model_response_proto_msgTypes[5]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use CreateModelResponseRequest_StreamOptions.ProtoReflect.Descriptor instead.
func (*CreateModelResponseRequest_StreamOptions) Descriptor() ([]byte, []int) {
	return file_api_v1_inference_server_model_response_proto_rawDescGZIP(), []int{0, 3}
}

func (x *CreateModelResponseRequest_StreamOptions) GetIncludeObfuscation() bool {
	if x != nil {
		return x.IncludeObfuscation
	}
	return false
}

type CreateModelResponseRequest_Text struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	Format    *CreateModelResponseRequest_Text_Format `protobuf:"bytes,1,opt,name=format,proto3" json:"format,omitempty"`
	Verbosity string                                  `protobuf:"bytes,2,opt,name=verbosity,proto3" json:"verbosity,omitempty"`
}

func (x *CreateModelResponseRequest_Text) Reset() {
	*x = CreateModelResponseRequest_Text{}
	if protoimpl.UnsafeEnabled {
		mi := &file_api_v1_inference_server_model_response_proto_msgTypes[6]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *CreateModelResponseRequest_Text) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*CreateModelResponseRequest_Text) ProtoMessage() {}

func (x *CreateModelResponseRequest_Text) ProtoReflect() protoreflect.Message {
	mi := &file_api_v1_inference_server_model_response_proto_msgTypes[6]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use CreateModelResponseRequest_Text.ProtoReflect.Descriptor instead.
func (*CreateModelResponseRequest_Text) Descriptor() ([]byte, []int) {
	return file_api_v1_inference_server_model_response_proto_rawDescGZIP(), []int{0, 4}
}

func (x *CreateModelResponseRequest_Text) GetFormat() *CreateModelResponseRequest_Text_Format {
	if x != nil {
		return x.Format
	}
	return nil
}

func (x *CreateModelResponseRequest_Text) GetVerbosity() string {
	if x != nil {
		return x.Verbosity
	}
	return ""
}

type CreateModelResponseRequest_ToolChoice struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	Type string `protobuf:"bytes,1,opt,name=type,proto3" json:"type,omitempty"`
	// name is meaningful for the hosted tool, function tool, MC tool, and custom tool.
	Name string `protobuf:"bytes,2,opt,name=name,proto3" json:"name,omitempty"`
	// mode is meaningful for the allowed tools.
	Mode string `protobuf:"bytes,3,opt,name=mode,proto3" json:"mode,omitempty"`
	// encoded_tools is meaningful for the allowed tools. It is a base64 encoded JSON object.
	//
	// The original value in the "tools" field is stripped by the server and converted
	// to "encoded_tools".
	//
	// The value of the field is converted back to the "tools" field when the request is being
	// sent to vLLM.
	EncodedTools string `protobuf:"bytes,4,opt,name=encoded_tools,json=encodedTools,proto3" json:"encoded_tools,omitempty"`
	// server_label is meaningful for the MCP tool.
	ServerLabel string `protobuf:"bytes,5,opt,name=server_label,json=serverLabel,proto3" json:"server_label,omitempty"`
}

func (x *CreateModelResponseRequest_ToolChoice) Reset() {
	*x = CreateModelResponseRequest_ToolChoice{}
	if protoimpl.UnsafeEnabled {
		mi := &file_api_v1_inference_server_model_response_proto_msgTypes[7]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *CreateModelResponseRequest_ToolChoice) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*CreateModelResponseRequest_ToolChoice) ProtoMessage() {}

func (x *CreateModelResponseRequest_ToolChoice) ProtoReflect() protoreflect.Message {
	mi := &file_api_v1_inference_server_model_response_proto_msgTypes[7]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use CreateModelResponseRequest_ToolChoice.ProtoReflect.Descriptor instead.
func (*CreateModelResponseRequest_ToolChoice) Descriptor() ([]byte, []int) {
	return file_api_v1_inference_server_model_response_proto_rawDescGZIP(), []int{0, 5}
}

func (x *CreateModelResponseRequest_ToolChoice) GetType() string {
	if x != nil {
		return x.Type
	}
	return ""
}

func (x *CreateModelResponseRequest_ToolChoice) GetName() string {
	if x != nil {
		return x.Name
	}
	return ""
}

func (x *CreateModelResponseRequest_ToolChoice) GetMode() string {
	if x != nil {
		return x.Mode
	}
	return ""
}

func (x *CreateModelResponseRequest_ToolChoice) GetEncodedTools() string {
	if x != nil {
		return x.EncodedTools
	}
	return ""
}

func (x *CreateModelResponseRequest_ToolChoice) GetServerLabel() string {
	if x != nil {
		return x.ServerLabel
	}
	return ""
}

type CreateModelResponseRequest_Input_Content struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	Type string `protobuf:"bytes,1,opt,name=type,proto3" json:"type,omitempty"`
	// This field is meaningful when the type is "input_text".
	Text string `protobuf:"bytes,2,opt,name=text,proto3" json:"text,omitempty"`
	// These fields are meaningful when the type is "input_image".
	Detail   string `protobuf:"bytes,3,opt,name=detail,proto3" json:"detail,omitempty"`
	ImageUrl string `protobuf:"bytes,4,opt,name=image_url,json=imageUrl,proto3" json:"image_url,omitempty"`
	// This field is meaningful when the type is "input_image" or "input_file".
	FileId string `protobuf:"bytes,5,opt,name=file_id,json=fileId,proto3" json:"file_id,omitempty"`
	// These fields are meaningful when the type is "input_file".
	FileData string `protobuf:"bytes,6,opt,name=file_data,json=fileData,proto3" json:"file_data,omitempty"`
	FileUrl  string `protobuf:"bytes,7,opt,name=file_url,json=fileUrl,proto3" json:"file_url,omitempty"`
	Filename string `protobuf:"bytes,8,opt,name=filename,proto3" json:"filename,omitempty"`
}

func (x *CreateModelResponseRequest_Input_Content) Reset() {
	*x = CreateModelResponseRequest_Input_Content{}
	if protoimpl.UnsafeEnabled {
		mi := &file_api_v1_inference_server_model_response_proto_msgTypes[9]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *CreateModelResponseRequest_Input_Content) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*CreateModelResponseRequest_Input_Content) ProtoMessage() {}

func (x *CreateModelResponseRequest_Input_Content) ProtoReflect() protoreflect.Message {
	mi := &file_api_v1_inference_server_model_response_proto_msgTypes[9]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use CreateModelResponseRequest_Input_Content.ProtoReflect.Descriptor instead.
func (*CreateModelResponseRequest_Input_Content) Descriptor() ([]byte, []int) {
	return file_api_v1_inference_server_model_response_proto_rawDescGZIP(), []int{0, 0, 0}
}

func (x *CreateModelResponseRequest_Input_Content) GetType() string {
	if x != nil {
		return x.Type
	}
	return ""
}

func (x *CreateModelResponseRequest_Input_Content) GetText() string {
	if x != nil {
		return x.Text
	}
	return ""
}

func (x *CreateModelResponseRequest_Input_Content) GetDetail() string {
	if x != nil {
		return x.Detail
	}
	return ""
}

func (x *CreateModelResponseRequest_Input_Content) GetImageUrl() string {
	if x != nil {
		return x.ImageUrl
	}
	return ""
}

func (x *CreateModelResponseRequest_Input_Content) GetFileId() string {
	if x != nil {
		return x.FileId
	}
	return ""
}

func (x *CreateModelResponseRequest_Input_Content) GetFileData() string {
	if x != nil {
		return x.FileData
	}
	return ""
}

func (x *CreateModelResponseRequest_Input_Content) GetFileUrl() string {
	if x != nil {
		return x.FileUrl
	}
	return ""
}

func (x *CreateModelResponseRequest_Input_Content) GetFilename() string {
	if x != nil {
		return x.Filename
	}
	return ""
}

type CreateModelResponseRequest_Text_Format struct {
	state         protoimpl.MessageState
	sizeCache     protoimpl.SizeCache
	unknownFields protoimpl.UnknownFields

	// Set to "text", "json_schema", or "json_object".
	Type string `protobuf:"bytes,1,opt,name=type,proto3" json:"type,omitempty"`
	// The following fields are only meaningful when the type is "json_schema".
	Name string `protobuf:"bytes,2,opt,name=name,proto3" json:"name,omitempty"`
	// encoded_schema is a base64 encoded JSON Schema object.
	//
	// The original value in the "schema" field is stripped by the server and converted
	// to "encoded_schema".
	//
	// The value of the field is converted back to the "schema" field when the request is being
	// sent to vLLM.
	EncodedSchema string `protobuf:"bytes,3,opt,name=encoded_schema,json=encodedSchema,proto3" json:"encoded_schema,omitempty"`
	Description   string `protobuf:"bytes,4,opt,name=description,proto3" json:"description,omitempty"`
	Strict        bool   `protobuf:"varint,5,opt,name=strict,proto3" json:"strict,omitempty"`
}

func (x *CreateModelResponseRequest_Text_Format) Reset() {
	*x = CreateModelResponseRequest_Text_Format{}
	if protoimpl.UnsafeEnabled {
		mi := &file_api_v1_inference_server_model_response_proto_msgTypes[10]
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		ms.StoreMessageInfo(mi)
	}
}

func (x *CreateModelResponseRequest_Text_Format) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*CreateModelResponseRequest_Text_Format) ProtoMessage() {}

func (x *CreateModelResponseRequest_Text_Format) ProtoReflect() protoreflect.Message {
	mi := &file_api_v1_inference_server_model_response_proto_msgTypes[10]
	if protoimpl.UnsafeEnabled && x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use CreateModelResponseRequest_Text_Format.ProtoReflect.Descriptor instead.
func (*CreateModelResponseRequest_Text_Format) Descriptor() ([]byte, []int) {
	return file_api_v1_inference_server_model_response_proto_rawDescGZIP(), []int{0, 4, 0}
}

func (x *CreateModelResponseRequest_Text_Format) GetType() string {
	if x != nil {
		return x.Type
	}
	return ""
}

func (x *CreateModelResponseRequest_Text_Format) GetName() string {
	if x != nil {
		return x.Name
	}
	return ""
}

func (x *CreateModelResponseRequest_Text_Format) GetEncodedSchema() string {
	if x != nil {
		return x.EncodedSchema
	}
	return ""
}

func (x *CreateModelResponseRequest_Text_Format) GetDescription() string {
	if x != nil {
		return x.Description
	}
	return ""
}

func (x *CreateModelResponseRequest_Text_Format) GetStrict() bool {
	if x != nil {
		return x.Strict
	}
	return false
}

var File_api_v1_inference_server_model_response_proto protoreflect.FileDescriptor

var file_api_v1_inference_server_model_response_proto_rawDesc = []byte{
	0x0a, 0x2c, 0x61, 0x70, 0x69, 0x2f, 0x76, 0x31, 0x2f, 0x69, 0x6e, 0x66, 0x65, 0x72, 0x65, 0x6e,
	0x63, 0x65, 0x5f, 0x73, 0x65, 0x72, 0x76, 0x65, 0x72, 0x5f, 0x6d, 0x6f, 0x64, 0x65, 0x6c, 0x5f,
	0x72, 0x65, 0x73, 0x70, 0x6f, 0x6e, 0x73, 0x65, 0x2e, 0x70, 0x72, 0x6f, 0x74, 0x6f, 0x12, 0x1c,
	0x6c, 0x6c, 0x6d, 0x61, 0x72, 0x69, 0x6e, 0x65, 0x72, 0x2e, 0x72, 0x65, 0x73, 0x70, 0x6f, 0x6e,
	0x73, 0x65, 0x2e, 0x73, 0x65, 0x72, 0x76, 0x65, 0x72, 0x2e, 0x76, 0x31, 0x1a, 0x1c, 0x67, 0x6f,
	0x6f, 0x67, 0x6c, 0x65, 0x2f, 0x61, 0x70, 0x69, 0x2f, 0x61, 0x6e, 0x6e, 0x6f, 0x74, 0x61, 0x74,
	0x69, 0x6f, 0x6e, 0x73, 0x2e, 0x70, 0x72, 0x6f, 0x74, 0x6f, 0x22, 0xef, 0x13, 0x0a, 0x1a, 0x43,
	0x72, 0x65, 0x61, 0x74, 0x65, 0x4d, 0x6f, 0x64, 0x65, 0x6c, 0x52, 0x65, 0x73, 0x70, 0x6f, 0x6e,
	0x73, 0x65, 0x52, 0x65, 0x71, 0x75, 0x65, 0x73, 0x74, 0x12, 0x1e, 0x0a, 0x0a, 0x62, 0x61, 0x63,
	0x6b, 0x67, 0x72, 0x6f, 0x75, 0x6e, 0x64, 0x18, 0x01, 0x20, 0x01, 0x28, 0x08, 0x52, 0x0a, 0x62,
	0x61, 0x63, 0x6b, 0x67, 0x72, 0x6f, 0x75, 0x6e, 0x64, 0x12, 0x18, 0x0a, 0x07, 0x69, 0x6e, 0x63,
	0x6c, 0x75, 0x64, 0x65, 0x18, 0x02, 0x20, 0x03, 0x28, 0x09, 0x52, 0x07, 0x69, 0x6e, 0x63, 0x6c,
	0x75, 0x64, 0x65, 0x12, 0x54, 0x0a, 0x05, 0x69, 0x6e, 0x70, 0x75, 0x74, 0x18, 0x03, 0x20, 0x03,
	0x28, 0x0b, 0x32, 0x3e, 0x2e, 0x6c, 0x6c, 0x6d, 0x61, 0x72, 0x69, 0x6e, 0x65, 0x72, 0x2e, 0x72,
	0x65, 0x73, 0x70, 0x6f, 0x6e, 0x73, 0x65, 0x2e, 0x73, 0x65, 0x72, 0x76, 0x65, 0x72, 0x2e, 0x76,
	0x31, 0x2e, 0x43, 0x72, 0x65, 0x61, 0x74, 0x65, 0x4d, 0x6f, 0x64, 0x65, 0x6c, 0x52, 0x65, 0x73,
	0x70, 0x6f, 0x6e, 0x73, 0x65, 0x52, 0x65, 0x71, 0x75, 0x65, 0x73, 0x74, 0x2e, 0x49, 0x6e, 0x70,
	0x75, 0x74, 0x52, 0x05, 0x69, 0x6e, 0x70, 0x75, 0x74, 0x12, 0x22, 0x0a, 0x0c, 0x69, 0x6e, 0x73,
	0x74, 0x72, 0x75, 0x63, 0x74, 0x69, 0x6f, 0x6e, 0x73, 0x18, 0x04, 0x20, 0x01, 0x28, 0x09, 0x52,
	0x0c, 0x69, 0x6e, 0x73, 0x74, 0x72, 0x75, 0x63, 0x74, 0x69, 0x6f, 0x6e, 0x73, 0x12, 0x2a, 0x0a,
	0x11, 0x6d, 0x61, 0x78, 0x5f, 0x6f, 0x75, 0x74, 0x70, 0x75, 0x74, 0x5f, 0x74, 0x6f, 0x6b, 0x65,
	0x6e, 0x73, 0x18, 0x05, 0x20, 0x01, 0x28, 0x05, 0x52, 0x0f, 0x6d, 0x61, 0x78, 0x4f, 0x75, 0x74,
	0x70, 0x75, 0x74, 0x54, 0x6f, 0x6b, 0x65, 0x6e, 0x73, 0x12, 0x24, 0x0a, 0x0e, 0x6d, 0x61, 0x78,
	0x5f, 0x74, 0x6f, 0x6f, 0x6c, 0x5f, 0x63, 0x61, 0x6c, 0x6c, 0x73, 0x18, 0x06, 0x20, 0x01, 0x28,
	0x05, 0x52, 0x0c, 0x6d, 0x61, 0x78, 0x54, 0x6f, 0x6f, 0x6c, 0x43, 0x61, 0x6c, 0x6c, 0x73, 0x12,
	0x62, 0x0a, 0x08, 0x6d, 0x65, 0x74, 0x61, 0x64, 0x61, 0x74, 0x61, 0x18, 0x07, 0x20, 0x03, 0x28,
	0x0b, 0x32, 0x46, 0x2e, 0x6c, 0x6c, 0x6d, 0x61, 0x72, 0x69, 0x6e, 0x65, 0x72, 0x2e, 0x72, 0x65,
	0x73, 0x70, 0x6f, 0x6e, 0x73, 0x65, 0x2e, 0x73, 0x65, 0x72, 0x76, 0x65, 0x72, 0x2e, 0x76, 0x31,
	0x2e, 0x43, 0x72, 0x65, 0x61, 0x74, 0x65, 0x4d, 0x6f, 0x64, 0x65, 0x6c, 0x52, 0x65, 0x73, 0x70,
	0x6f, 0x6e, 0x73, 0x65, 0x52, 0x65, 0x71, 0x75, 0x65, 0x73, 0x74, 0x2e, 0x4d, 0x65, 0x74, 0x61,
	0x64, 0x61, 0x74, 0x61, 0x45, 0x6e, 0x74, 0x72, 0x79, 0x52, 0x08, 0x6d, 0x65, 0x74, 0x61, 0x64,
	0x61, 0x74, 0x61, 0x12, 0x14, 0x0a, 0x05, 0x6d, 0x6f, 0x64, 0x65, 0x6c, 0x18, 0x08, 0x20, 0x01,
	0x28, 0x09, 0x52, 0x05, 0x6d, 0x6f, 0x64, 0x65, 0x6c, 0x12, 0x2e, 0x0a, 0x13, 0x70, 0x61, 0x72,
	0x61, 0x6c, 0x6c, 0x65, 0x6c, 0x5f, 0x74, 0x6f, 0x6f, 0x6c, 0x5f, 0x63, 0x61, 0x6c, 0x6c, 0x73,
	0x18, 0x09, 0x20, 0x01, 0x28, 0x08, 0x52, 0x11, 0x70, 0x61, 0x72, 0x61, 0x6c, 0x6c, 0x65, 0x6c,
	0x54, 0x6f, 0x6f, 0x6c, 0x43, 0x61, 0x6c, 0x6c, 0x73, 0x12, 0x30, 0x0a, 0x14, 0x70, 0x72, 0x65,
	0x76, 0x69, 0x6f, 0x75, 0x73, 0x5f, 0x72, 0x65, 0x73, 0x70, 0x6f, 0x6e, 0x73, 0x65, 0x5f, 0x69,
	0x64, 0x18, 0x0a, 0x20, 0x01, 0x28, 0x09, 0x52, 0x12, 0x70, 0x72, 0x65, 0x76, 0x69, 0x6f, 0x75,
	0x73, 0x52, 0x65, 0x73, 0x70, 0x6f, 0x6e, 0x73, 0x65, 0x49, 0x64, 0x12, 0x57, 0x0a, 0x06, 0x70,
	0x72, 0x6f, 0x6d, 0x70, 0x74, 0x18, 0x0b, 0x20, 0x01, 0x28, 0x0b, 0x32, 0x3f, 0x2e, 0x6c, 0x6c,
	0x6d, 0x61, 0x72, 0x69, 0x6e, 0x65, 0x72, 0x2e, 0x72, 0x65, 0x73, 0x70, 0x6f, 0x6e, 0x73, 0x65,
	0x2e, 0x73, 0x65, 0x72, 0x76, 0x65, 0x72, 0x2e, 0x76, 0x31, 0x2e, 0x43, 0x72, 0x65, 0x61, 0x74,
	0x65, 0x4d, 0x6f, 0x64, 0x65, 0x6c, 0x52, 0x65, 0x73, 0x70, 0x6f, 0x6e, 0x73, 0x65, 0x52, 0x65,
	0x71, 0x75, 0x65, 0x73, 0x74, 0x2e, 0x50, 0x72, 0x6f, 0x6d, 0x70, 0x74, 0x52, 0x06, 0x70, 0x72,
	0x6f, 0x6d, 0x70, 0x74, 0x12, 0x28, 0x0a, 0x10, 0x70, 0x72, 0x6f, 0x6d, 0x70, 0x74, 0x5f, 0x63,
	0x61, 0x63, 0x68, 0x65, 0x5f, 0x6b, 0x65, 0x79, 0x18, 0x0c, 0x20, 0x01, 0x28, 0x09, 0x52, 0x0e,
	0x70, 0x72, 0x6f, 0x6d, 0x70, 0x74, 0x43, 0x61, 0x63, 0x68, 0x65, 0x4b, 0x65, 0x79, 0x12, 0x60,
	0x0a, 0x09, 0x72, 0x65, 0x61, 0x73, 0x6f, 0x6e, 0x69, 0x6e, 0x67, 0x18, 0x0d, 0x20, 0x01, 0x28,
	0x0b, 0x32, 0x42, 0x2e, 0x6c, 0x6c, 0x6d, 0x61, 0x72, 0x69, 0x6e, 0x65, 0x72, 0x2e, 0x72, 0x65,
	0x73, 0x70, 0x6f, 0x6e, 0x73, 0x65, 0x2e, 0x73, 0x65, 0x72, 0x76, 0x65, 0x72, 0x2e, 0x76, 0x31,
	0x2e, 0x43, 0x72, 0x65, 0x61, 0x74, 0x65, 0x4d, 0x6f, 0x64, 0x65, 0x6c, 0x52, 0x65, 0x73, 0x70,
	0x6f, 0x6e, 0x73, 0x65, 0x52, 0x65, 0x71, 0x75, 0x65, 0x73, 0x74, 0x2e, 0x52, 0x65, 0x61, 0x73,
	0x6f, 0x6e, 0x69, 0x6e, 0x67, 0x52, 0x09, 0x72, 0x65, 0x61, 0x73, 0x6f, 0x6e, 0x69, 0x6e, 0x67,
	0x12, 0x2b, 0x0a, 0x11, 0x73, 0x61, 0x66, 0x65, 0x74, 0x79, 0x5f, 0x69, 0x64, 0x65, 0x6e, 0x74,
	0x69, 0x66, 0x69, 0x65, 0x72, 0x18, 0x0e, 0x20, 0x01, 0x28, 0x09, 0x52, 0x10, 0x73, 0x61, 0x66,
	0x65, 0x74, 0x79, 0x49, 0x64, 0x65, 0x6e, 0x74, 0x69, 0x66, 0x69, 0x65, 0x72, 0x12, 0x21, 0x0a,
	0x0c, 0x73, 0x65, 0x72, 0x76, 0x69, 0x63, 0x65, 0x5f, 0x74, 0x69, 0x65, 0x72, 0x18, 0x0f, 0x20,
	0x01, 0x28, 0x09, 0x52, 0x0b, 0x73, 0x65, 0x72, 0x76, 0x69, 0x63, 0x65, 0x54, 0x69, 0x65, 0x72,
	0x12, 0x14, 0x0a, 0x05, 0x73, 0x74, 0x6f, 0x72, 0x65, 0x18, 0x10, 0x20, 0x01, 0x28, 0x08, 0x52,
	0x05, 0x73, 0x74, 0x6f, 0x72, 0x65, 0x12, 0x16, 0x0a, 0x06, 0x73, 0x74, 0x72, 0x65, 0x61, 0x6d,
	0x18, 0x11, 0x20, 0x01, 0x28, 0x08, 0x52, 0x06, 0x73, 0x74, 0x72, 0x65, 0x61, 0x6d, 0x12, 0x6d,
	0x0a, 0x0e, 0x73, 0x74, 0x72, 0x65, 0x61, 0x6d, 0x5f, 0x6f, 0x70, 0x74, 0x69, 0x6f, 0x6e, 0x73,
	0x18, 0x12, 0x20, 0x01, 0x28, 0x0b, 0x32, 0x46, 0x2e, 0x6c, 0x6c, 0x6d, 0x61, 0x72, 0x69, 0x6e,
	0x65, 0x72, 0x2e, 0x72, 0x65, 0x73, 0x70, 0x6f, 0x6e, 0x73, 0x65, 0x2e, 0x73, 0x65, 0x72, 0x76,
	0x65, 0x72, 0x2e, 0x76, 0x31, 0x2e, 0x43, 0x72, 0x65, 0x61, 0x74, 0x65, 0x4d, 0x6f, 0x64, 0x65,
	0x6c, 0x52, 0x65, 0x73, 0x70, 0x6f, 0x6e, 0x73, 0x65, 0x52, 0x65, 0x71, 0x75, 0x65, 0x73, 0x74,
	0x2e, 0x53, 0x74, 0x72, 0x65, 0x61, 0x6d, 0x4f, 0x70, 0x74, 0x69, 0x6f, 0x6e, 0x73, 0x52, 0x0d,
	0x73, 0x74, 0x72, 0x65, 0x61, 0x6d, 0x4f, 0x70, 0x74, 0x69, 0x6f, 0x6e, 0x73, 0x12, 0x20, 0x0a,
	0x0b, 0x74, 0x65, 0x6d, 0x70, 0x65, 0x72, 0x61, 0x74, 0x75, 0x72, 0x65, 0x18, 0x13, 0x20, 0x01,
	0x28, 0x01, 0x52, 0x0b, 0x74, 0x65, 0x6d, 0x70, 0x65, 0x72, 0x61, 0x74, 0x75, 0x72, 0x65, 0x12,
	0x2c, 0x0a, 0x12, 0x69, 0x73, 0x5f, 0x74, 0x65, 0x6d, 0x70, 0x65, 0x72, 0x61, 0x74, 0x75, 0x72,
	0x65, 0x5f, 0x73, 0x65, 0x74, 0x18, 0x14, 0x20, 0x01, 0x28, 0x08, 0x52, 0x10, 0x69, 0x73, 0x54,
	0x65, 0x6d, 0x70, 0x65, 0x72, 0x61, 0x74, 0x75, 0x72, 0x65, 0x53, 0x65, 0x74, 0x12, 0x51, 0x0a,
	0x04, 0x74, 0x65, 0x78, 0x74, 0x18, 0x15, 0x20, 0x01, 0x28, 0x0b, 0x32, 0x3d, 0x2e, 0x6c, 0x6c,
	0x6d, 0x61, 0x72, 0x69, 0x6e, 0x65, 0x72, 0x2e, 0x72, 0x65, 0x73, 0x70, 0x6f, 0x6e, 0x73, 0x65,
	0x2e, 0x73, 0x65, 0x72, 0x76, 0x65, 0x72, 0x2e, 0x76, 0x31, 0x2e, 0x43, 0x72, 0x65, 0x61, 0x74,
	0x65, 0x4d, 0x6f, 0x64, 0x65, 0x6c, 0x52, 0x65, 0x73, 0x70, 0x6f, 0x6e, 0x73, 0x65, 0x52, 0x65,
	0x71, 0x75, 0x65, 0x73, 0x74, 0x2e, 0x54, 0x65, 0x78, 0x74, 0x52, 0x04, 0x74, 0x65, 0x78, 0x74,
	0x12, 0x1f, 0x0a, 0x0b, 0x74, 0x6f, 0x6f, 0x6c, 0x5f, 0x63, 0x68, 0x6f, 0x69, 0x63, 0x65, 0x18,
	0x16, 0x20, 0x01, 0x28, 0x09, 0x52, 0x0a, 0x74, 0x6f, 0x6f, 0x6c, 0x43, 0x68, 0x6f, 0x69, 0x63,
	0x65, 0x12, 0x71, 0x0a, 0x12, 0x74, 0x6f, 0x6f, 0x6c, 0x5f, 0x63, 0x68, 0x6f, 0x69, 0x63, 0x65,
	0x5f, 0x6f, 0x62, 0x6a, 0x65, 0x63, 0x74, 0x18, 0x17, 0x20, 0x01, 0x28, 0x0b, 0x32, 0x43, 0x2e,
	0x6c, 0x6c, 0x6d, 0x61, 0x72, 0x69, 0x6e, 0x65, 0x72, 0x2e, 0x72, 0x65, 0x73, 0x70, 0x6f, 0x6e,
	0x73, 0x65, 0x2e, 0x73, 0x65, 0x72, 0x76, 0x65, 0x72, 0x2e, 0x76, 0x31, 0x2e, 0x43, 0x72, 0x65,
	0x61, 0x74, 0x65, 0x4d, 0x6f, 0x64, 0x65, 0x6c, 0x52, 0x65, 0x73, 0x70, 0x6f, 0x6e, 0x73, 0x65,
	0x52, 0x65, 0x71, 0x75, 0x65, 0x73, 0x74, 0x2e, 0x54, 0x6f, 0x6f, 0x6c, 0x43, 0x68, 0x6f, 0x69,
	0x63, 0x65, 0x52, 0x10, 0x74, 0x6f, 0x6f, 0x6c, 0x43, 0x68, 0x6f, 0x69, 0x63, 0x65, 0x4f, 0x62,
	0x6a, 0x65, 0x63, 0x74, 0x12, 0x21, 0x0a, 0x0c, 0x74, 0x6f, 0x70, 0x5f, 0x6c, 0x6f, 0x67, 0x70,
	0x72, 0x6f, 0x62, 0x73, 0x18, 0x18, 0x20, 0x01, 0x28, 0x05, 0x52, 0x0b, 0x74, 0x6f, 0x70, 0x4c,
	0x6f, 0x67, 0x70, 0x72, 0x6f, 0x62, 0x73, 0x12, 0x13, 0x0a, 0x05, 0x74, 0x6f, 0x70, 0x5f, 0x70,
	0x18, 0x19, 0x20, 0x01, 0x28, 0x01, 0x52, 0x04, 0x74, 0x6f, 0x70, 0x50, 0x12, 0x1f, 0x0a, 0x0c,
	0x69, 0x73, 0x5f, 0x74, 0x6f, 0x70, 0x5f, 0x70, 0x5f, 0x73, 0x65, 0x74, 0x18, 0x1a, 0x20, 0x01,
	0x28, 0x08, 0x52, 0x09, 0x69, 0x73, 0x54, 0x6f, 0x70, 0x50, 0x53, 0x65, 0x74, 0x12, 0x1e, 0x0a,
	0x0a, 0x74, 0x72, 0x75, 0x6e, 0x63, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x18, 0x1b, 0x20, 0x01, 0x28,
	0x08, 0x52, 0x0a, 0x74, 0x72, 0x75, 0x6e, 0x63, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x12, 0x12, 0x0a,
	0x04, 0x75, 0x73, 0x65, 0x72, 0x18, 0x1c, 0x20, 0x01, 0x28, 0x09, 0x52, 0x04, 0x75, 0x73, 0x65,
	0x72, 0x1a, 0x8f, 0x03, 0x0a, 0x05, 0x49, 0x6e, 0x70, 0x75, 0x74, 0x12, 0x12, 0x0a, 0x04, 0x74,
	0x79, 0x70, 0x65, 0x18, 0x01, 0x20, 0x01, 0x28, 0x09, 0x52, 0x04, 0x74, 0x79, 0x70, 0x65, 0x12,
	0x60, 0x0a, 0x07, 0x63, 0x6f, 0x6e, 0x74, 0x65, 0x6e, 0x74, 0x18, 0x02, 0x20, 0x03, 0x28, 0x0b,
	0x32, 0x46, 0x2e, 0x6c, 0x6c, 0x6d, 0x61, 0x72, 0x69, 0x6e, 0x65, 0x72, 0x2e, 0x72, 0x65, 0x73,
	0x70, 0x6f, 0x6e, 0x73, 0x65, 0x2e, 0x73, 0x65, 0x72, 0x76, 0x65, 0x72, 0x2e, 0x76, 0x31, 0x2e,
	0x43, 0x72, 0x65, 0x61, 0x74, 0x65, 0x4d, 0x6f, 0x64, 0x65, 0x6c, 0x52, 0x65, 0x73, 0x70, 0x6f,
	0x6e, 0x73, 0x65, 0x52, 0x65, 0x71, 0x75, 0x65, 0x73, 0x74, 0x2e, 0x49, 0x6e, 0x70, 0x75, 0x74,
	0x2e, 0x43, 0x6f, 0x6e, 0x74, 0x65, 0x6e, 0x74, 0x52, 0x07, 0x63, 0x6f, 0x6e, 0x74, 0x65, 0x6e,
	0x74, 0x12, 0x12, 0x0a, 0x04, 0x72, 0x6f, 0x6c, 0x65, 0x18, 0x03, 0x20, 0x01, 0x28, 0x09, 0x52,
	0x04, 0x72, 0x6f, 0x6c, 0x65, 0x12, 0x16, 0x0a, 0x06, 0x73, 0x74, 0x61, 0x74, 0x75, 0x73, 0x18,
	0x04, 0x20, 0x01, 0x28, 0x09, 0x52, 0x06, 0x73, 0x74, 0x61, 0x74, 0x75, 0x73, 0x12, 0x0e, 0x0a,
	0x02, 0x69, 0x64, 0x18, 0x05, 0x20, 0x01, 0x28, 0x09, 0x52, 0x02, 0x69, 0x64, 0x1a, 0xd3, 0x01,
	0x0a, 0x07, 0x43, 0x6f, 0x6e, 0x74, 0x65, 0x6e, 0x74, 0x12, 0x12, 0x0a, 0x04, 0x74, 0x79, 0x70,
	0x65, 0x18, 0x01, 0x20, 0x01, 0x28, 0x09, 0x52, 0x04, 0x74, 0x79, 0x70, 0x65, 0x12, 0x12, 0x0a,
	0x04, 0x74, 0x65, 0x78, 0x74, 0x18, 0x02, 0x20, 0x01, 0x28, 0x09, 0x52, 0x04, 0x74, 0x65, 0x78,
	0x74, 0x12, 0x16, 0x0a, 0x06, 0x64, 0x65, 0x74, 0x61, 0x69, 0x6c, 0x18, 0x03, 0x20, 0x01, 0x28,
	0x09, 0x52, 0x06, 0x64, 0x65, 0x74, 0x61, 0x69, 0x6c, 0x12, 0x1b, 0x0a, 0x09, 0x69, 0x6d, 0x61,
	0x67, 0x65, 0x5f, 0x75, 0x72, 0x6c, 0x18, 0x04, 0x20, 0x01, 0x28, 0x09, 0x52, 0x08, 0x69, 0x6d,
	0x61, 0x67, 0x65, 0x55, 0x72, 0x6c, 0x12, 0x17, 0x0a, 0x07, 0x66, 0x69, 0x6c, 0x65, 0x5f, 0x69,
	0x64, 0x18, 0x05, 0x20, 0x01, 0x28, 0x09, 0x52, 0x06, 0x66, 0x69, 0x6c, 0x65, 0x49, 0x64, 0x12,
	0x1b, 0x0a, 0x09, 0x66, 0x69, 0x6c, 0x65, 0x5f, 0x64, 0x61, 0x74, 0x61, 0x18, 0x06, 0x20, 0x01,
	0x28, 0x09, 0x52, 0x08, 0x66, 0x69, 0x6c, 0x65, 0x44, 0x61, 0x74, 0x61, 0x12, 0x19, 0x0a, 0x08,
	0x66, 0x69, 0x6c, 0x65, 0x5f, 0x75, 0x72, 0x6c, 0x18, 0x07, 0x20, 0x01, 0x28, 0x09, 0x52, 0x07,
	0x66, 0x69, 0x6c, 0x65, 0x55, 0x72, 0x6c, 0x12, 0x1a, 0x0a, 0x08, 0x66, 0x69, 0x6c, 0x65, 0x6e,
	0x61, 0x6d, 0x65, 0x18, 0x08, 0x20, 0x01, 0x28, 0x09, 0x52, 0x08, 0x66, 0x69, 0x6c, 0x65, 0x6e,
	0x61, 0x6d, 0x65, 0x1a, 0x32, 0x0a, 0x06, 0x50, 0x72, 0x6f, 0x6d, 0x70, 0x74, 0x12, 0x0e, 0x0a,
	0x02, 0x69, 0x64, 0x18, 0x01, 0x20, 0x01, 0x28, 0x09, 0x52, 0x02, 0x69, 0x64, 0x12, 0x18, 0x0a,
	0x07, 0x76, 0x65, 0x72, 0x73, 0x69, 0x6f, 0x6e, 0x18, 0x03, 0x20, 0x01, 0x28, 0x09, 0x52, 0x07,
	0x76, 0x65, 0x72, 0x73, 0x69, 0x6f, 0x6e, 0x1a, 0x68, 0x0a, 0x09, 0x52, 0x65, 0x61, 0x73, 0x6f,
	0x6e, 0x69, 0x6e, 0x67, 0x12, 0x16, 0x0a, 0x06, 0x65, 0x66, 0x66, 0x6f, 0x72, 0x74, 0x18, 0x01,
	0x20, 0x01, 0x28, 0x09, 0x52, 0x06, 0x65, 0x66, 0x66, 0x6f, 0x72, 0x74, 0x12, 0x29, 0x0a, 0x10,
	0x67, 0x65, 0x6e, 0x65, 0x72, 0x61, 0x74, 0x65, 0x5f, 0x73, 0x75, 0x6d, 0x6d, 0x61, 0x72, 0x79,
	0x18, 0x02, 0x20, 0x01, 0x28, 0x09, 0x52, 0x0f, 0x67, 0x65, 0x6e, 0x65, 0x72, 0x61, 0x74, 0x65,
	0x53, 0x75, 0x6d, 0x6d, 0x61, 0x72, 0x79, 0x12, 0x18, 0x0a, 0x07, 0x73, 0x75, 0x6d, 0x6d, 0x61,
	0x72, 0x79, 0x18, 0x03, 0x20, 0x01, 0x28, 0x09, 0x52, 0x07, 0x73, 0x75, 0x6d, 0x6d, 0x61, 0x72,
	0x79, 0x1a, 0x40, 0x0a, 0x0d, 0x53, 0x74, 0x72, 0x65, 0x61, 0x6d, 0x4f, 0x70, 0x74, 0x69, 0x6f,
	0x6e, 0x73, 0x12, 0x2f, 0x0a, 0x13, 0x69, 0x6e, 0x63, 0x6c, 0x75, 0x64, 0x65, 0x5f, 0x6f, 0x62,
	0x66, 0x75, 0x73, 0x63, 0x61, 0x74, 0x69, 0x6f, 0x6e, 0x18, 0x01, 0x20, 0x01, 0x28, 0x08, 0x52,
	0x12, 0x69, 0x6e, 0x63, 0x6c, 0x75, 0x64, 0x65, 0x4f, 0x62, 0x66, 0x75, 0x73, 0x63, 0x61, 0x74,
	0x69, 0x6f, 0x6e, 0x1a, 0x96, 0x02, 0x0a, 0x04, 0x54, 0x65, 0x78, 0x74, 0x12, 0x5c, 0x0a, 0x06,
	0x66, 0x6f, 0x72, 0x6d, 0x61, 0x74, 0x18, 0x01, 0x20, 0x01, 0x28, 0x0b, 0x32, 0x44, 0x2e, 0x6c,
	0x6c, 0x6d, 0x61, 0x72, 0x69, 0x6e, 0x65, 0x72, 0x2e, 0x72, 0x65, 0x73, 0x70, 0x6f, 0x6e, 0x73,
	0x65, 0x2e, 0x73, 0x65, 0x72, 0x76, 0x65, 0x72, 0x2e, 0x76, 0x31, 0x2e, 0x43, 0x72, 0x65, 0x61,
	0x74, 0x65, 0x4d, 0x6f, 0x64, 0x65, 0x6c, 0x52, 0x65, 0x73, 0x70, 0x6f, 0x6e, 0x73, 0x65, 0x52,
	0x65, 0x71, 0x75, 0x65, 0x73, 0x74, 0x2e, 0x54, 0x65, 0x78, 0x74, 0x2e, 0x46, 0x6f, 0x72, 0x6d,
	0x61, 0x74, 0x52, 0x06, 0x66, 0x6f, 0x72, 0x6d, 0x61, 0x74, 0x12, 0x1c, 0x0a, 0x09, 0x76, 0x65,
	0x72, 0x62, 0x6f, 0x73, 0x69, 0x74, 0x79, 0x18, 0x02, 0x20, 0x01, 0x28, 0x09, 0x52, 0x09, 0x76,
	0x65, 0x72, 0x62, 0x6f, 0x73, 0x69, 0x74, 0x79, 0x1a, 0x91, 0x01, 0x0a, 0x06, 0x46, 0x6f, 0x72,
	0x6d, 0x61, 0x74, 0x12, 0x12, 0x0a, 0x04, 0x74, 0x79, 0x70, 0x65, 0x18, 0x01, 0x20, 0x01, 0x28,
	0x09, 0x52, 0x04, 0x74, 0x79, 0x70, 0x65, 0x12, 0x12, 0x0a, 0x04, 0x6e, 0x61, 0x6d, 0x65, 0x18,
	0x02, 0x20, 0x01, 0x28, 0x09, 0x52, 0x04, 0x6e, 0x61, 0x6d, 0x65, 0x12, 0x25, 0x0a, 0x0e, 0x65,
	0x6e, 0x63, 0x6f, 0x64, 0x65, 0x64, 0x5f, 0x73, 0x63, 0x68, 0x65, 0x6d, 0x61, 0x18, 0x03, 0x20,
	0x01, 0x28, 0x09, 0x52, 0x0d, 0x65, 0x6e, 0x63, 0x6f, 0x64, 0x65, 0x64, 0x53, 0x63, 0x68, 0x65,
	0x6d, 0x61, 0x12, 0x20, 0x0a, 0x0b, 0x64, 0x65, 0x73, 0x63, 0x72, 0x69, 0x70, 0x74, 0x69, 0x6f,
	0x6e, 0x18, 0x04, 0x20, 0x01, 0x28, 0x09, 0x52, 0x0b, 0x64, 0x65, 0x73, 0x63, 0x72, 0x69, 0x70,
	0x74, 0x69, 0x6f, 0x6e, 0x12, 0x16, 0x0a, 0x06, 0x73, 0x74, 0x72, 0x69, 0x63, 0x74, 0x18, 0x05,
	0x20, 0x01, 0x28, 0x08, 0x52, 0x06, 0x73, 0x74, 0x72, 0x69, 0x63, 0x74, 0x1a, 0x90, 0x01, 0x0a,
	0x0a, 0x54, 0x6f, 0x6f, 0x6c, 0x43, 0x68, 0x6f, 0x69, 0x63, 0x65, 0x12, 0x12, 0x0a, 0x04, 0x74,
	0x79, 0x70, 0x65, 0x18, 0x01, 0x20, 0x01, 0x28, 0x09, 0x52, 0x04, 0x74, 0x79, 0x70, 0x65, 0x12,
	0x12, 0x0a, 0x04, 0x6e, 0x61, 0x6d, 0x65, 0x18, 0x02, 0x20, 0x01, 0x28, 0x09, 0x52, 0x04, 0x6e,
	0x61, 0x6d, 0x65, 0x12, 0x12, 0x0a, 0x04, 0x6d, 0x6f, 0x64, 0x65, 0x18, 0x03, 0x20, 0x01, 0x28,
	0x09, 0x52, 0x04, 0x6d, 0x6f, 0x64, 0x65, 0x12, 0x23, 0x0a, 0x0d, 0x65, 0x6e, 0x63, 0x6f, 0x64,
	0x65, 0x64, 0x5f, 0x74, 0x6f, 0x6f, 0x6c, 0x73, 0x18, 0x04, 0x20, 0x01, 0x28, 0x09, 0x52, 0x0c,
	0x65, 0x6e, 0x63, 0x6f, 0x64, 0x65, 0x64, 0x54, 0x6f, 0x6f, 0x6c, 0x73, 0x12, 0x21, 0x0a, 0x0c,
	0x73, 0x65, 0x72, 0x76, 0x65, 0x72, 0x5f, 0x6c, 0x61, 0x62, 0x65, 0x6c, 0x18, 0x05, 0x20, 0x01,
	0x28, 0x09, 0x52, 0x0b, 0x73, 0x65, 0x72, 0x76, 0x65, 0x72, 0x4c, 0x61, 0x62, 0x65, 0x6c, 0x1a,
	0x3b, 0x0a, 0x0d, 0x4d, 0x65, 0x74, 0x61, 0x64, 0x61, 0x74, 0x61, 0x45, 0x6e, 0x74, 0x72, 0x79,
	0x12, 0x10, 0x0a, 0x03, 0x6b, 0x65, 0x79, 0x18, 0x01, 0x20, 0x01, 0x28, 0x09, 0x52, 0x03, 0x6b,
	0x65, 0x79, 0x12, 0x14, 0x0a, 0x05, 0x76, 0x61, 0x6c, 0x75, 0x65, 0x18, 0x02, 0x20, 0x01, 0x28,
	0x09, 0x52, 0x05, 0x76, 0x61, 0x6c, 0x75, 0x65, 0x3a, 0x02, 0x38, 0x01, 0x22, 0x0f, 0x0a, 0x0d,
	0x4d, 0x6f, 0x64, 0x65, 0x6c, 0x52, 0x65, 0x73, 0x70, 0x6f, 0x6e, 0x73, 0x65, 0x42, 0x2f, 0x5a,
	0x2d, 0x67, 0x69, 0x74, 0x68, 0x75, 0x62, 0x2e, 0x63, 0x6f, 0x6d, 0x2f, 0x6c, 0x6c, 0x6d, 0x61,
	0x72, 0x69, 0x6e, 0x65, 0x72, 0x2f, 0x69, 0x6e, 0x66, 0x65, 0x72, 0x65, 0x6e, 0x63, 0x65, 0x2d,
	0x6d, 0x61, 0x6e, 0x61, 0x67, 0x65, 0x72, 0x2f, 0x61, 0x70, 0x69, 0x2f, 0x76, 0x31, 0x62, 0x06,
	0x70, 0x72, 0x6f, 0x74, 0x6f, 0x33,
}

var (
	file_api_v1_inference_server_model_response_proto_rawDescOnce sync.Once
	file_api_v1_inference_server_model_response_proto_rawDescData = file_api_v1_inference_server_model_response_proto_rawDesc
)

func file_api_v1_inference_server_model_response_proto_rawDescGZIP() []byte {
	file_api_v1_inference_server_model_response_proto_rawDescOnce.Do(func() {
		file_api_v1_inference_server_model_response_proto_rawDescData = protoimpl.X.CompressGZIP(file_api_v1_inference_server_model_response_proto_rawDescData)
	})
	return file_api_v1_inference_server_model_response_proto_rawDescData
}

var file_api_v1_inference_server_model_response_proto_msgTypes = make([]protoimpl.MessageInfo, 11)
var file_api_v1_inference_server_model_response_proto_goTypes = []interface{}{
	(*CreateModelResponseRequest)(nil),               // 0: llmariner.response.server.v1.CreateModelResponseRequest
	(*ModelResponse)(nil),                            // 1: llmariner.response.server.v1.ModelResponse
	(*CreateModelResponseRequest_Input)(nil),         // 2: llmariner.response.server.v1.CreateModelResponseRequest.Input
	(*CreateModelResponseRequest_Prompt)(nil),        // 3: llmariner.response.server.v1.CreateModelResponseRequest.Prompt
	(*CreateModelResponseRequest_Reasoning)(nil),     // 4: llmariner.response.server.v1.CreateModelResponseRequest.Reasoning
	(*CreateModelResponseRequest_StreamOptions)(nil), // 5: llmariner.response.server.v1.CreateModelResponseRequest.StreamOptions
	(*CreateModelResponseRequest_Text)(nil),          // 6: llmariner.response.server.v1.CreateModelResponseRequest.Text
	(*CreateModelResponseRequest_ToolChoice)(nil),    // 7: llmariner.response.server.v1.CreateModelResponseRequest.ToolChoice
	nil, // 8: llmariner.response.server.v1.CreateModelResponseRequest.MetadataEntry
	(*CreateModelResponseRequest_Input_Content)(nil), // 9: llmariner.response.server.v1.CreateModelResponseRequest.Input.Content
	(*CreateModelResponseRequest_Text_Format)(nil),   // 10: llmariner.response.server.v1.CreateModelResponseRequest.Text.Format
}
var file_api_v1_inference_server_model_response_proto_depIdxs = []int32{
	2,  // 0: llmariner.response.server.v1.CreateModelResponseRequest.input:type_name -> llmariner.response.server.v1.CreateModelResponseRequest.Input
	8,  // 1: llmariner.response.server.v1.CreateModelResponseRequest.metadata:type_name -> llmariner.response.server.v1.CreateModelResponseRequest.MetadataEntry
	3,  // 2: llmariner.response.server.v1.CreateModelResponseRequest.prompt:type_name -> llmariner.response.server.v1.CreateModelResponseRequest.Prompt
	4,  // 3: llmariner.response.server.v1.CreateModelResponseRequest.reasoning:type_name -> llmariner.response.server.v1.CreateModelResponseRequest.Reasoning
	5,  // 4: llmariner.response.server.v1.CreateModelResponseRequest.stream_options:type_name -> llmariner.response.server.v1.CreateModelResponseRequest.StreamOptions
	6,  // 5: llmariner.response.server.v1.CreateModelResponseRequest.text:type_name -> llmariner.response.server.v1.CreateModelResponseRequest.Text
	7,  // 6: llmariner.response.server.v1.CreateModelResponseRequest.tool_choice_object:type_name -> llmariner.response.server.v1.CreateModelResponseRequest.ToolChoice
	9,  // 7: llmariner.response.server.v1.CreateModelResponseRequest.Input.content:type_name -> llmariner.response.server.v1.CreateModelResponseRequest.Input.Content
	10, // 8: llmariner.response.server.v1.CreateModelResponseRequest.Text.format:type_name -> llmariner.response.server.v1.CreateModelResponseRequest.Text.Format
	9,  // [9:9] is the sub-list for method output_type
	9,  // [9:9] is the sub-list for method input_type
	9,  // [9:9] is the sub-list for extension type_name
	9,  // [9:9] is the sub-list for extension extendee
	0,  // [0:9] is the sub-list for field type_name
}

func init() { file_api_v1_inference_server_model_response_proto_init() }
func file_api_v1_inference_server_model_response_proto_init() {
	if File_api_v1_inference_server_model_response_proto != nil {
		return
	}
	if !protoimpl.UnsafeEnabled {
		file_api_v1_inference_server_model_response_proto_msgTypes[0].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*CreateModelResponseRequest); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_api_v1_inference_server_model_response_proto_msgTypes[1].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*ModelResponse); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_api_v1_inference_server_model_response_proto_msgTypes[2].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*CreateModelResponseRequest_Input); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_api_v1_inference_server_model_response_proto_msgTypes[3].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*CreateModelResponseRequest_Prompt); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_api_v1_inference_server_model_response_proto_msgTypes[4].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*CreateModelResponseRequest_Reasoning); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_api_v1_inference_server_model_response_proto_msgTypes[5].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*CreateModelResponseRequest_StreamOptions); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_api_v1_inference_server_model_response_proto_msgTypes[6].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*CreateModelResponseRequest_Text); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_api_v1_inference_server_model_response_proto_msgTypes[7].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*CreateModelResponseRequest_ToolChoice); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_api_v1_inference_server_model_response_proto_msgTypes[9].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*CreateModelResponseRequest_Input_Content); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
		file_api_v1_inference_server_model_response_proto_msgTypes[10].Exporter = func(v interface{}, i int) interface{} {
			switch v := v.(*CreateModelResponseRequest_Text_Format); i {
			case 0:
				return &v.state
			case 1:
				return &v.sizeCache
			case 2:
				return &v.unknownFields
			default:
				return nil
			}
		}
	}
	type x struct{}
	out := protoimpl.TypeBuilder{
		File: protoimpl.DescBuilder{
			GoPackagePath: reflect.TypeOf(x{}).PkgPath(),
			RawDescriptor: file_api_v1_inference_server_model_response_proto_rawDesc,
			NumEnums:      0,
			NumMessages:   11,
			NumExtensions: 0,
			NumServices:   0,
		},
		GoTypes:           file_api_v1_inference_server_model_response_proto_goTypes,
		DependencyIndexes: file_api_v1_inference_server_model_response_proto_depIdxs,
		MessageInfos:      file_api_v1_inference_server_model_response_proto_msgTypes,
	}.Build()
	File_api_v1_inference_server_model_response_proto = out.File
	file_api_v1_inference_server_model_response_proto_rawDesc = nil
	file_api_v1_inference_server_model_response_proto_goTypes = nil
	file_api_v1_inference_server_model_response_proto_depIdxs = nil
}
