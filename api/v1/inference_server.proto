syntax = "proto3";

package llmoperator.chat.server.v1;

import "google/api/annotations.proto";

option go_package = "github.com/llm-operator/inference-manager/api/v1";

// The API specification fllows OpenAPI API specification (https://platform.openai.com/docs/api-reference/chat).

message CreateChatCompletionRequest {
  // Message has fields for system message, user message, assistant message, and tool message.
  message Message {
    message ToolCall {
      message Function {
	string name  = 1;
	string arguments = 2;
      }
      string id = 1;
      string type = 2;
      Function function = 3;
    }

    // The type of content varies. For eample, it is string or array for UserMesasge.
    string content = 1;
    string role = 2;
    string name = 3;
    repeated ToolCall tool_calls = 4;
  }

  message ResponseFormat {
    string type = 1;
  }

  message Tool {
    message Function {
      string description = 1;
      string name = 2;
      // TODO(kenji): Revisit this. This specifies parameters the functions accepts,
      // described as a JSON Schema object.
      string parameters = 3;
    }
    string type = 1;
    Function function = 2;
  }

  message ToolChoice {
    // TODO(guangrui): revisit on how to assign string value of ToolChoice.
    string choice = 1;
    string type = 2;
    message Function {
      string name = 1;
    }
    Function function = 3;
  }

  // TODO(kenji): Revisit this.
  repeated Message messages = 1;
  string model = 2;
  double frequency_penalty = 3;
  map<string, double> logit_bias = 4;
  bool logprobs = 5;
  int32 top_logprobs = 6;
  int32 max_tokens = 7;
  int32 n = 8;
  double presence_penalty = 9;
  ResponseFormat response_format = 10;
  int32 seed = 11;
  // string / arrary/ null
  repeated string stop = 12;
  bool stream = 13;
  double temperature = 14;
  double top_p = 15;
  repeated Tool tools = 16;
  ToolChoice tool_choice = 17;
  string user = 18;
}

message ToolCall {
  message Function {
    string name  = 1;
    string arguments = 2;
  }
  string id = 1;
  string type = 2;
  Function function = 3;
}

message Logprobs {
  message Content {
    message TopLogprobs {
      string token = 1;
      double logprob = 2;
      bytes bytes = 3;
    }

    string token = 1;
    double logprob = 2;
    // A list of integers representing the UTF-8 bytes representation of the token.
    bytes bytes = 3;
    TopLogprobs top_logprobs = 4;
  }
  repeated Content content = 1;
}

message Usage {
  int32 completion_tokens = 1;
  int32 prompt_tokens = 2;
  int32 total_tokens = 3;
}

message ChatCompletion {
  message Choice {
    message Message {

      string content = 1;
      repeated ToolCall tool_calls = 2;
      string role = 3;
    }

    string finish_reason = 1;
    int32 index = 2;
    Message message = 3;
    Logprobs logprobs = 4;
  }

  string id = 1;
  repeated Choice choices = 2;
  int32 created = 3;
  string model = 4;
  string system_fingerprint = 5;
  string object = 6;
  Usage usage = 7;
}

message ChatCompletionChunk {
  message Choice {
    message Delta {
      message ToolCall {
	message Function {
	  string name  = 1;
	  string arguments = 2;
	}
	string id = 1;
	string type = 2;
	Function function = 3;
      }

      string content = 1;
      repeated ToolCall tool_calls = 2;
      string role = 3;
    }

    Delta delta = 1;
    string finish_reason = 2;
    int32 index = 3;
    Logprobs logprobs = 4;
  }

  string id = 1;
  repeated Choice choices = 2;
  int32 created = 3;
  string model = 4;
  string system_fingerprint = 5;
  string object = 6;
  Usage usage = 7;
}

// RagFunction is used to unmarshal the json string specified in `Parameters` of Tool message.
message RagFunction {
  string vector_store_name = 1;
}

service ChatService {
  // CreateChatCompletion is implemented as an HTTP handler without gRPC
  // as gRPC gateway does not support server-sent events.
}


// Define legacy completion
// (https://platform.openai.com/docs/api-reference/completions/create).

message CreateCompletionRequest {
  message StreamOption {
    bool include_usage = 1;
  }
  string model = 1;
  // This can be a string or an array of strings, but we use string assuming that it is more common.
  string prompt = 2;
  int32 best_of = 3;
  bool echo = 4;
  double frequency_penalty = 5;
  map<string, double> logit_bias = 6;
  int32 logprobs = 7;
  int32 max_tokens = 8;
  int32 n = 9;
  double presence_penalty = 10;
  int32 seed = 11;
  repeated string stop = 12;
  bool stream = 13;
  StreamOption stream_option = 14;
  string suffix = 15;
  double temperature = 16;
  double top_p = 17;
  string user = 18;
}

message Completion {
  message Choice {
    message Logprobs {
      // TODO: Revisit this. The types of the fields are not clearly specified in the spec.
      int32 text_offset = 1;
      double token_logprobs = 2;
      string tokens = 3;
      double top_logprobs = 4;
    }
    string finish_reason = 1;
    int32 index = 2;
    Logprobs logprobs = 3;
    string text = 4;
  }

  string id = 1;
  repeated Choice choices = 2;
  int32 created = 3;
  string model = 4;
  string system_fingerprint = 5;
  string object = 6;

  Usage usage = 7;
}
