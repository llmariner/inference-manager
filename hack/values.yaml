global:
  auth:
    enable: false
  usageSender:
    enable: false

prepare:
  redis:
    createSecret: false
  workerRegistration:
    createSecret: true
    secret:
      key: default-cluster-registration-key-secret

inference-manager-server:
  rateLimit:
    storeType: memory
    rate: 1
    period: 30s
    burst: 10
  version: latest
  image:
    repository: llmariner/inference-manager-server
    pullPolicy: Never

inference-manager-engine:
  version: latest
  image:
    repository: llmariner/inference-manager-engine
    pullPolicy: Never
  replicaCount: 1
  model:
    default:
      runtimeName: ollama
      resources:
        limits:
          cpu: 0
          memory: 0
        requests:
          cpu: 0
          memory: 0
    overrides:
      gemma2:2b:
        preloaded: true
  componentStatusSender:
    enable: false

model-manager-loader:
  runOnce: false
  downloader:
    kind: ollama
  baseModels:
  - gemma2:2b
  - deepseek-r1:1.5b
  componentStatusSender:
    enable: false
